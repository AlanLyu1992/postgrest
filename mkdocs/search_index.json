{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction\n\n\nPostgREST is a standalone web server that turns your database directly into a RESTful API. The structural constraints and permissions in the database determine the API endpoints and operations.\n\n\nThis guide explains how to install the software and provides practical examples of its use. You'll learn how to build a fast, versioned, secure API and how to deploy it to production.\n\n\nThe project has a friendly and growing community. Here are some ways to get help or get involved:\n\n\n\n\nThe project \nchat room\n\n\nReport or search \nissues\n\n\n\n\nMotivation\n\n\nUsing PostgREST is an alternative to manual CRUD programming. Custom API servers suffer problems. Writing business logic often duplicates, ignores or hobbles database structure. Object-relational mapping is a leaky abstraction leading to slow imperative code. The PostgREST philosophy establishes a single declarative source of truth: the data itself.\n\n\nDeclarative Programming\n\n\nIt's easier to ask Postgres to join data for you and let its query planner figure out the details than to loop through rows yourself. It's easier to assign permissions to db objects than to add guards in controllers. (This is especially true for cascading permissions in data dependencies.) It's easier set constraints than to litter code with sanity checks.\n\n\nLeakproof Abstraction\n\n\nThere is no ORM involved. Creating new views happens in SQL with known performance implications. A database administrator can now create an API from scratch with no custom programming. \n\n\nEmbracing the Relational Model\n\n\nIn 1970 E. F. Codd criticized the then-dominant hierarchical model of databases in his article \nA Relational Model of Data for Large Shared Data Banks\n. Reading the article reveals a striking similarity between hierarchical databases and nested http routes. With PostgREST we attempt to use flexible filtering and embedding rather than nested routes.\n\n\nOne Thing Well\n\n\nPostgREST has a focused scope. It works well with other tools like Nginx. This forces you to cleanly separate the data-centric CRUD operations from other concerns. Use a collection of sharp tools rather than building a big ball of mud.\n\n\nShared Improvements\n\n\nAs with any open source project, we all gain from features and fixes in the tool. It's more beneficial than improvements locked inextricably within custom codebases.\n\n\nMyths\n\n\nYou have to make tons of stored procs and triggers\n\n\nModern PostgreSQL features like auto-updatable views and computed columns make this mostly unnecessary. Triggers do play a part, but generally not for irksome boilerplate. When they are required triggers are preferable to ad-hoc app code anyway, since the former work reliably for any codepath.\n\n\nExposing the database destroys encapsulation\n\n\nPostgREST does versioning through database schemas. This allows you to expose tables and views without making the app brittle. Underlying tables can be superseded and hidden behind public facing views. The chapter about versioning shows how to do this.\n\n\nConventions\n\n\nThis guide contains highlighted notes and tangential information interspersed with the text.\n\n\n\n    \nDesign Consideration\n\n\n    \nContains history which informed the current design. Sometimes it discusses unavoidable tradeoffs or a point of theory.\n\n\n\n\n\n\n    \nInvitation to Contribute\n\n\n    \nPoints out things we know we want to add or improve. They might give you ideas for ways to contribute to the project.\n\n\n\n\n\n\n    \nDeprecation Warning\n\n\n    \nAlerts you to features which will be removed in the next major (breaking) release.", 
            "title": "Home"
        }, 
        {
            "location": "/#introduction", 
            "text": "PostgREST is a standalone web server that turns your database directly into a RESTful API. The structural constraints and permissions in the database determine the API endpoints and operations.  This guide explains how to install the software and provides practical examples of its use. You'll learn how to build a fast, versioned, secure API and how to deploy it to production.  The project has a friendly and growing community. Here are some ways to get help or get involved:   The project  chat room  Report or search  issues   Motivation  Using PostgREST is an alternative to manual CRUD programming. Custom API servers suffer problems. Writing business logic often duplicates, ignores or hobbles database structure. Object-relational mapping is a leaky abstraction leading to slow imperative code. The PostgREST philosophy establishes a single declarative source of truth: the data itself.  Declarative Programming  It's easier to ask Postgres to join data for you and let its query planner figure out the details than to loop through rows yourself. It's easier to assign permissions to db objects than to add guards in controllers. (This is especially true for cascading permissions in data dependencies.) It's easier set constraints than to litter code with sanity checks.  Leakproof Abstraction  There is no ORM involved. Creating new views happens in SQL with known performance implications. A database administrator can now create an API from scratch with no custom programming.   Embracing the Relational Model  In 1970 E. F. Codd criticized the then-dominant hierarchical model of databases in his article  A Relational Model of Data for Large Shared Data Banks . Reading the article reveals a striking similarity between hierarchical databases and nested http routes. With PostgREST we attempt to use flexible filtering and embedding rather than nested routes.  One Thing Well  PostgREST has a focused scope. It works well with other tools like Nginx. This forces you to cleanly separate the data-centric CRUD operations from other concerns. Use a collection of sharp tools rather than building a big ball of mud.  Shared Improvements  As with any open source project, we all gain from features and fixes in the tool. It's more beneficial than improvements locked inextricably within custom codebases.  Myths  You have to make tons of stored procs and triggers  Modern PostgreSQL features like auto-updatable views and computed columns make this mostly unnecessary. Triggers do play a part, but generally not for irksome boilerplate. When they are required triggers are preferable to ad-hoc app code anyway, since the former work reliably for any codepath.  Exposing the database destroys encapsulation  PostgREST does versioning through database schemas. This allows you to expose tables and views without making the app brittle. Underlying tables can be superseded and hidden behind public facing views. The chapter about versioning shows how to do this.  Conventions  This guide contains highlighted notes and tangential information interspersed with the text.  \n     Design Consideration \n\n     Contains history which informed the current design. Sometimes it discusses unavoidable tradeoffs or a point of theory.   \n     Invitation to Contribute \n\n     Points out things we know we want to add or improve. They might give you ideas for ways to contribute to the project.   \n     Deprecation Warning \n\n     Alerts you to features which will be removed in the next major (breaking) release.", 
            "title": "Introduction"
        }, 
        {
            "location": "/install/server/", 
            "text": "Installation\n\n\nInstalling from Pre-Built Release\n\n\nThe \nrelease page\n has precompiled binaries for Mac OS X and 64-bit Ubuntu. Next extract the tarball and run the binary inside with no arguments to see usage instructions:\n\n\n# Untar the release (available at https://github.com/begriffs/postgrest/releases/latest)\n\n$ tar zxf postgrest-0.2.12.0-osx.tar.xz\n\n# Try running it\n$ ./postgrest\n\n# You should see a usage help message\n\n\n\n\n\n    \nInvitation to Contribute\n\n\n    \nI currently build the binaries manually for each version. We need to set up an automated build matrix for various architectures. It should support 32- and 64-bit versions of\n\n    \nScientific Linux 6\nCentOS\nRHEL 6\n\n\n    Also it would be good to create a package for apt.\n\n\n\n\n\nWe'll learn the meaning of the command line flags later, but here is a minimal example of running the app. It does all operations as user \npostgres\n, including for unauthenticated requests.\n\n\n$ ./postgrest -d dbname -U postgres -a postgres --v1schema public\n\n\n\n\nBuilding from Source\n\n\nWhen a prebuilt binary does not exist for your system you can build the project from source. You'll also need to do this if you want to help with development. \nStack\n makes it easy. It will install any necessary Haskell dependencies on your system.\n\n\n\n\nInstall Stack\n for your platform\n\n\nBuild the project\n\n\n\n\ngit clone https://github.com/begriffs/postgrest.git\ncd postgrest\nstack build\n\n\n\n\n\n\nRun the server\n\n\n\n\nstack exec postgrest -- arg1 arg2\n# ... your arguments after the double dashes\n\n\n\n\nIf you want to run the test suite, stack can do that too: \nstack test\n.\n\n\nInstall via Homebrew (Mac OS X)\n\n\nYou can use the Homebrew package manager to install PostgREST on Mac\n\n\n# Ensure brew is up to date\nbrew update\n\n# Check for any problems with brew's setup\nbrew doctor\n\n# Install the postgrest package\nbrew install postgrest\n\n\n\n\nThis will automatically install PostgreSQL as a dependency (see the \nInstalling PostgreSQL\n section for setup instructions). The process tends to take around 15 minutes to install the package and its dependencies.\n\n\nAfter installation completes, the tool is added to your $PATH and can be used from anywhere with:\n\n\npostgrest --help\n\n\n\n\nInstalling PostgreSQL\n\n\nTo use PostgREST you will need an underlying database. You can use something like Amazon \nRDS\n but installing your own locally is cheaper and more convenient for development.\n\n\n\n\nInstructions for OS X\n\n\nInstructions for Ubuntu 14.04", 
            "title": "The Server"
        }, 
        {
            "location": "/install/server/#installation", 
            "text": "Installing from Pre-Built Release  The  release page  has precompiled binaries for Mac OS X and 64-bit Ubuntu. Next extract the tarball and run the binary inside with no arguments to see usage instructions:  # Untar the release (available at https://github.com/begriffs/postgrest/releases/latest)\n\n$ tar zxf postgrest-0.2.12.0-osx.tar.xz\n\n# Try running it\n$ ./postgrest\n\n# You should see a usage help message  \n     Invitation to Contribute \n\n     I currently build the binaries manually for each version. We need to set up an automated build matrix for various architectures. It should support 32- and 64-bit versions of\n\n     Scientific Linux 6 CentOS RHEL 6 \n\n    Also it would be good to create a package for apt.   We'll learn the meaning of the command line flags later, but here is a minimal example of running the app. It does all operations as user  postgres , including for unauthenticated requests.  $ ./postgrest -d dbname -U postgres -a postgres --v1schema public  Building from Source  When a prebuilt binary does not exist for your system you can build the project from source. You'll also need to do this if you want to help with development.  Stack  makes it easy. It will install any necessary Haskell dependencies on your system.   Install Stack  for your platform  Build the project   git clone https://github.com/begriffs/postgrest.git\ncd postgrest\nstack build   Run the server   stack exec postgrest -- arg1 arg2\n# ... your arguments after the double dashes  If you want to run the test suite, stack can do that too:  stack test .  Install via Homebrew (Mac OS X)  You can use the Homebrew package manager to install PostgREST on Mac  # Ensure brew is up to date\nbrew update\n\n# Check for any problems with brew's setup\nbrew doctor\n\n# Install the postgrest package\nbrew install postgrest  This will automatically install PostgreSQL as a dependency (see the  Installing PostgreSQL  section for setup instructions). The process tends to take around 15 minutes to install the package and its dependencies.  After installation completes, the tool is added to your $PATH and can be used from anywhere with:  postgrest --help  Installing PostgreSQL  To use PostgREST you will need an underlying database. You can use something like Amazon  RDS  but installing your own locally is cheaper and more convenient for development.   Instructions for OS X  Instructions for Ubuntu 14.04", 
            "title": "Installation"
        }, 
        {
            "location": "/install/ecosystem/", 
            "text": "Ecosystem\n\n\nClient-Side Libraries\n\n\n\n\nmithril.postgrest\n - Mithril plugin to create and authenticate requests\n\n\nlewisjared/postgrest-request\n - node interface to postgrest instances\n\n\nJarvusInnovations/jarvus-postgrest-apikit\n - Sencha framework package for binding models/stores/proxies to PostgREST tables\n\n\n\n\nExtensions\n\n\n\n\nsrid/spas\n - allow file uploads and basic auth\n\n\n\n\nExample Apps\n\n\n\n\ntimwis/ext-postgrest-crud\n - browser-based spreadsheet\n\n\nsrid/chronicle\n - tracking a tree of personal memories\n\n\nbegriffs/postgrest-example\n - how to configure a db for use as an API\n\n\nmarmelab/ng-admin-postgrest\n - automatic database admin panel\n\n\ntyrchen/goodfilm\n - example film api\n\n\n\n\nIn Production\n\n\n\n\nCatarse", 
            "title": "Ecosystem"
        }, 
        {
            "location": "/install/ecosystem/#ecosystem", 
            "text": "Client-Side Libraries   mithril.postgrest  - Mithril plugin to create and authenticate requests  lewisjared/postgrest-request  - node interface to postgrest instances  JarvusInnovations/jarvus-postgrest-apikit  - Sencha framework package for binding models/stores/proxies to PostgREST tables   Extensions   srid/spas  - allow file uploads and basic auth   Example Apps   timwis/ext-postgrest-crud  - browser-based spreadsheet  srid/chronicle  - tracking a tree of personal memories  begriffs/postgrest-example  - how to configure a db for use as an API  marmelab/ng-admin-postgrest  - automatic database admin panel  tyrchen/goodfilm  - example film api   In Production   Catarse", 
            "title": "Ecosystem"
        }, 
        {
            "location": "/api/reading/", 
            "text": "Requesting Information\n\n\nTables and Views\n\n\n\n\n\u2705 Cacheable, prefetchable\n\n\n\u2705 Idempotent\n\n\n\n\nThe list of accessible tables and views is provided at\n\n\nGET /\n\n\n\n\nEvery view and table accessible by the active db role is exposed\nin a one-level deep route. For instance the full contents of a table\n\npeople\n is returned at\n\n\nGET /people\n\n\n\n\nThere are no \ndeeply/nested/routes\n. Each route provides \nOPTIONS\n,\n\nGET\n, \nPOST\n, \nPUT\n, \nPATCH\n, and \nDELETE\n verbs depending entirely\non database permissions.\n\n\n\n  \nDesign Consideration\n\n\n  \nWhy not provide nested routes? Many APIs allow nesting to\n  retrieve related information, such as \n/films/1/director\n.\n  We offer a more flexible mechanism instead to embed related\n  information, including many-to-many relationships. This is covered\n  in the section about Embedding.\n\n\n\n\n\nStored Procedures\n\n\n\n\n\u274c Cannot necessarily be cached or prefetched\n\n\n\u274c Not necessarily idempotent\n\n\n\n\nEvery stored procedure is accessible under the \n/rpc\n prefix. The\nAPI endpoint supports only POST which executes the function.\n\n\nPOST /rpc/proc_name\n\n\n\n\nPostgREST supports calling procedures with \nnamed\narguments\n.\nTo do so include a JSON object in the request payload and each\nkey/value of the object will become an argument.\n\n\n\n  \nDesign Consideration\n\n\n  \nWhy the /rpc prefix? One reason is to avoid name collisions\n  between views and procedures. It also helps emphasize to API\n  consumers that these functions are not normal restful things.\n  The functions can have arbitrary and surprising behavior, not\n  the standard \"post creates a resource\" thing that users expect\n  from the other routes.\n\n\n  \nWe considered allowing GET requests for functions that are\n  marked non-volatile but could not reconcile how to pass in\n  parameters. Query string arguments are reserved for shaping/filtering\n  the output, not providing input.\n\n\n\n\n\nFiltering\n\n\nFiltering Rows\n\n\nYou can filter result rows by adding conditions on columns, each\ncondition a query string parameter.  For instance, to return people\naged under 13 years old:\n\n\nGET /people?age=lt.13\n\n\n\n\nAdding multiple parameters conjoins the conditions:\n\n\nGET /people?age=gte.18\nstudent=is.true\n\n\n\n\nThese operators are available:\n\n\n\n\n\n\n\n\nabbreviation\n\n\nmeaning\n\n\n\n\n\n\n\n\n\n\neq\n\n\nequals\n\n\n\n\n\n\ngt\n\n\ngreater than\n\n\n\n\n\n\nlt\n\n\nless than\n\n\n\n\n\n\ngte\n\n\ngreater than or equal\n\n\n\n\n\n\nlte\n\n\nless than or equal\n\n\n\n\n\n\nlike\n\n\nLIKE operator (use * in place of %)\n\n\n\n\n\n\nilike\n\n\nILIKE operator (use * in place of %)\n\n\n\n\n\n\n@@\n\n\nfull-text search using to_tsquery\n\n\n\n\n\n\nis\n\n\nchecking for exact equality (null,true,false)\n\n\n\n\n\n\nin\n\n\none of a list of values e.g. \n?a=in.1,2,3\n\n\n\n\n\n\nnot\n\n\nnegates another operator, see below\n\n\n\n\n\n\n\n\nTo negate any operator, prefix it with \nnot\n like \n?a=not.eq.2\n.\n\n\nFor more complicated filters (such as those involving condition 1\n\nOR\n condition 2) you will have to create a new view in the database.\n\n\nFilters may be applied to \ncomputed\ncolumns\n\nas well as actual table/view columns, even though the computed\ncolumns will not appear in the output.\n\n\nFiltering Columns\n\n\nYou can customize which columns are returned by using the \nselect\n\nparameter:\n\n\nGET /people?select=age,height,weight\n\n\n\n\nTo cast the column types, add a double colon\n\n\nGET /people?select=age::text,height,weight\n\n\n\n\nNot all type coercions are possible, and you will get an error\ndescribing any problems from selection or type casting.\n\n\nThe \nselect\n keyword is reserved. You thus cannot filter rows based\non a column named select. Then again it is a reserved SQL keyword\ntoo, hence an unlikely column name.\n\n\nInside JSONB\n\n\nPostgreSQL \n=9.4.2 supports native JSON columns and can even index\nthem by internal keys using the \njsonb\n column type. PostgREST\nallows you to filter results by internal JSON object values. Use\nthe single- and double-arrows to path into and obtain values, e.g.\n\n\nGET /stuff?json_col-\na-\nb=eq.2\n\n\n\n\nThis query finds rows in \nstuff\n where \njson_col-\n'a'-\n'b'\n is\nequal to 2 (or \"2\" -- it coerces as needed). The final arrow must\nbe the double kind, \n-\n, or else PostgREST will not attempt to\nlook inside the JSON.\n\n\nOrdering\n\n\nThe reserved word \norder\n reorders the response rows.  It uses a\ncomma-separated list of columns and directions:\n\n\nGET /people?order=age.desc,height.asc\n\n\n\n\nIf no direction is specified it defaults to descending order:\n\n\nGET /people?order=age\n\n\n\n\nIf you care where nulls are sorted, add \nnullsfirst\n or \nnullslast\n:\n\n\nGET /people?order=age.nullsfirst\n\n\n\n\nLimiting and Pagination\n\n\nPagination by Limit-Offset\n\n\nPostgREST uses HTTP range headers for limiting and describing the\nsize of results. Every response contains the current range and total\nresults:\n\n\nRange-Unit: items\nContent-Range \u2192 0-14/15\n\n\n\n\nThis means items zero through fourteen are returned out of a total\nof fifteen -- i.e. all of them. This information is available in\nevery response and can help you render pagination controls on the\nclient. This is a RFC7233-compliant solution that keeps the response\nJSON cleaner.\n\n\nThe client can set the limit and offset of a request by setting the\n\nRange\n header. Translate the limit and offset into a range. To\nrequest the first five elements, include these request headers:\n\n\nRange-Unit: items\nRange: 0-4\n\n\n\n\nYou can also use open-ended ranges for an offset with no limit:\n\nRange: 10-\n.\n\n\nSuppressing Counts\n\n\nSometimes knowing the total row count of a query is unnecessary and\nonly adds extra cost to the database query. So you can skip the\ncount total using a \nPrefer\n header as:\n\n\nPrefer: count=none\n\n\n\n\nSo the PostgREST response will be something like:\n\n\nRange-Unit: items\nContent-Range \u2192 0-14/*\n\n\n\n\nEmbedding Foreign Entities\n\n\nSuppose you have a \nprojects\n table which references \nclients\n through\na foreign key called \nclient_id\n. When listing projects through the\nAPI you can have it embed the client within each project response.\nFor example,\n\n\nGET /projects?id=eq.1\nselect=id, name, clients(*)\n\n\n\n\nNotice this is the same \nselect\n keyword which is used to choose\nwhich columns to include. When a column name is followed by parentheses\nthat means to fetch the entire record and nest it. You include a\nlist of columns inside the parens, or asterisk to request all\ncolumns.\n\n\nThe embedding works for 1-N, N-1, and N-N relationships. That means\nyou could also ask for a client and all their projects:\n\n\nGET /clients?id=eq.42\nselect=id, name, projects(*)\n\n\n\n\nResponse Format\n\n\nQuery responses default to JSON but you can get them in CSV as well. Just make your request with the header\n\n\nAccept: text/csv\n\n\n\n\nSingular vs Plural\n\n\nMany APIs distinguish plural and singular resources, e.g.\n/stories\n\nvs \n/stories/1\n. Why do we use \n/stories?id=eq.1\n? It is because a\nsingle resource is for us a row determined by a primary key, and\nprimary keys can be \ncompound\n (meaning defined across more than\none column). The common urls come from a degenerate case of simple\n(and overwhelmingly numeric) primary keys often introduced automatically\nbe Object Relational Mapping.\n\n\nFor consistency's sake all these endpoints return a JSON array,\n\n/stories\n, \n/stories?genre=eq.mystery\n, \n/stories?id=eq.1\n. They\nare all filtering a bigger array. However you might want the\nlast one to return a single JSON object, not an array with one\nelement. There is currently an open issue to enable this.\n\n\nData Schema\n\n\nAs well as issuing a \nGET /\n to obtain a list of the tables, views,\nand stored procedures available, you can get more information about\nany particular endpoint.\n\n\nOPTIONS /my_view\n\n\n\n\nThis will include the row names, their types, primary key\ninformation, and foreign keys for the given table or view.\n\n\n\n    \nDeprecation Warning\n\n\n    \nAlthough we currently use the OPTIONS verb for this, some\n    people \nargue\n that\n    this is inappropriate. We are considering a \ndescribedby\n\n    header link instead.\n\n\n\n\n\nCORS\n\n\nPostgREST sets highly permissive cross origin resource sharing.  It\naccepts Ajax requests from any domain.", 
            "title": "Reading"
        }, 
        {
            "location": "/api/reading/#requesting-information", 
            "text": "Tables and Views   \u2705 Cacheable, prefetchable  \u2705 Idempotent   The list of accessible tables and views is provided at  GET /  Every view and table accessible by the active db role is exposed\nin a one-level deep route. For instance the full contents of a table people  is returned at  GET /people  There are no  deeply/nested/routes . Each route provides  OPTIONS , GET ,  POST ,  PUT ,  PATCH , and  DELETE  verbs depending entirely\non database permissions.  \n   Design Consideration \n\n   Why not provide nested routes? Many APIs allow nesting to\n  retrieve related information, such as  /films/1/director .\n  We offer a more flexible mechanism instead to embed related\n  information, including many-to-many relationships. This is covered\n  in the section about Embedding.   Stored Procedures   \u274c Cannot necessarily be cached or prefetched  \u274c Not necessarily idempotent   Every stored procedure is accessible under the  /rpc  prefix. The\nAPI endpoint supports only POST which executes the function.  POST /rpc/proc_name  PostgREST supports calling procedures with  named\narguments .\nTo do so include a JSON object in the request payload and each\nkey/value of the object will become an argument.  \n   Design Consideration \n\n   Why the /rpc prefix? One reason is to avoid name collisions\n  between views and procedures. It also helps emphasize to API\n  consumers that these functions are not normal restful things.\n  The functions can have arbitrary and surprising behavior, not\n  the standard \"post creates a resource\" thing that users expect\n  from the other routes. \n\n   We considered allowing GET requests for functions that are\n  marked non-volatile but could not reconcile how to pass in\n  parameters. Query string arguments are reserved for shaping/filtering\n  the output, not providing input.   Filtering  Filtering Rows  You can filter result rows by adding conditions on columns, each\ncondition a query string parameter.  For instance, to return people\naged under 13 years old:  GET /people?age=lt.13  Adding multiple parameters conjoins the conditions:  GET /people?age=gte.18 student=is.true  These operators are available:     abbreviation  meaning      eq  equals    gt  greater than    lt  less than    gte  greater than or equal    lte  less than or equal    like  LIKE operator (use * in place of %)    ilike  ILIKE operator (use * in place of %)    @@  full-text search using to_tsquery    is  checking for exact equality (null,true,false)    in  one of a list of values e.g.  ?a=in.1,2,3    not  negates another operator, see below     To negate any operator, prefix it with  not  like  ?a=not.eq.2 .  For more complicated filters (such as those involving condition 1 OR  condition 2) you will have to create a new view in the database.  Filters may be applied to  computed\ncolumns \nas well as actual table/view columns, even though the computed\ncolumns will not appear in the output.  Filtering Columns  You can customize which columns are returned by using the  select \nparameter:  GET /people?select=age,height,weight  To cast the column types, add a double colon  GET /people?select=age::text,height,weight  Not all type coercions are possible, and you will get an error\ndescribing any problems from selection or type casting.  The  select  keyword is reserved. You thus cannot filter rows based\non a column named select. Then again it is a reserved SQL keyword\ntoo, hence an unlikely column name.  Inside JSONB  PostgreSQL  =9.4.2 supports native JSON columns and can even index\nthem by internal keys using the  jsonb  column type. PostgREST\nallows you to filter results by internal JSON object values. Use\nthe single- and double-arrows to path into and obtain values, e.g.  GET /stuff?json_col- a- b=eq.2  This query finds rows in  stuff  where  json_col- 'a'- 'b'  is\nequal to 2 (or \"2\" -- it coerces as needed). The final arrow must\nbe the double kind,  - , or else PostgREST will not attempt to\nlook inside the JSON.  Ordering  The reserved word  order  reorders the response rows.  It uses a\ncomma-separated list of columns and directions:  GET /people?order=age.desc,height.asc  If no direction is specified it defaults to descending order:  GET /people?order=age  If you care where nulls are sorted, add  nullsfirst  or  nullslast :  GET /people?order=age.nullsfirst  Limiting and Pagination  Pagination by Limit-Offset  PostgREST uses HTTP range headers for limiting and describing the\nsize of results. Every response contains the current range and total\nresults:  Range-Unit: items\nContent-Range \u2192 0-14/15  This means items zero through fourteen are returned out of a total\nof fifteen -- i.e. all of them. This information is available in\nevery response and can help you render pagination controls on the\nclient. This is a RFC7233-compliant solution that keeps the response\nJSON cleaner.  The client can set the limit and offset of a request by setting the Range  header. Translate the limit and offset into a range. To\nrequest the first five elements, include these request headers:  Range-Unit: items\nRange: 0-4  You can also use open-ended ranges for an offset with no limit: Range: 10- .  Suppressing Counts  Sometimes knowing the total row count of a query is unnecessary and\nonly adds extra cost to the database query. So you can skip the\ncount total using a  Prefer  header as:  Prefer: count=none  So the PostgREST response will be something like:  Range-Unit: items\nContent-Range \u2192 0-14/*  Embedding Foreign Entities  Suppose you have a  projects  table which references  clients  through\na foreign key called  client_id . When listing projects through the\nAPI you can have it embed the client within each project response.\nFor example,  GET /projects?id=eq.1 select=id, name, clients(*)  Notice this is the same  select  keyword which is used to choose\nwhich columns to include. When a column name is followed by parentheses\nthat means to fetch the entire record and nest it. You include a\nlist of columns inside the parens, or asterisk to request all\ncolumns.  The embedding works for 1-N, N-1, and N-N relationships. That means\nyou could also ask for a client and all their projects:  GET /clients?id=eq.42 select=id, name, projects(*)  Response Format  Query responses default to JSON but you can get them in CSV as well. Just make your request with the header  Accept: text/csv  Singular vs Plural  Many APIs distinguish plural and singular resources, e.g. /stories \nvs  /stories/1 . Why do we use  /stories?id=eq.1 ? It is because a\nsingle resource is for us a row determined by a primary key, and\nprimary keys can be  compound  (meaning defined across more than\none column). The common urls come from a degenerate case of simple\n(and overwhelmingly numeric) primary keys often introduced automatically\nbe Object Relational Mapping.  For consistency's sake all these endpoints return a JSON array, /stories ,  /stories?genre=eq.mystery ,  /stories?id=eq.1 . They\nare all filtering a bigger array. However you might want the\nlast one to return a single JSON object, not an array with one\nelement. There is currently an open issue to enable this.  Data Schema  As well as issuing a  GET /  to obtain a list of the tables, views,\nand stored procedures available, you can get more information about\nany particular endpoint.  OPTIONS /my_view  This will include the row names, their types, primary key\ninformation, and foreign keys for the given table or view.  \n     Deprecation Warning \n\n     Although we currently use the OPTIONS verb for this, some\n    people  argue  that\n    this is inappropriate. We are considering a  describedby \n    header link instead.   CORS  PostgREST sets highly permissive cross origin resource sharing.  It\naccepts Ajax requests from any domain.", 
            "title": "Requesting Information"
        }, 
        {
            "location": "/api/writing/", 
            "text": "Updating Data\n\n\nRecord Creation\n\n\n\n\n\u274c Cannot be cached or prefetched\n\n\n\u274c Not idempotent\n\n\n\n\nTo create a row in a database table post a JSON object whose keys\nare the names of the columns you would like to create. Missing keys\nwill be set to default values when applicable.\n\n\nPOST /table_name\n{ \ncol1\n: \nvalue1\n, \ncol2\n: \nvalue2\n }\n\n\n\n\nThe response will include a \nLocation\n header describing where to\nfind the new object. If you would like to get the full object back\nin the response to your request, include the header \nPrefer:\nreturn=representation\n. That way you won't have to make another\nHTTP call to discover properties that may have been filled in on\nthe server side.\n\n\nBulk Insertion\n\n\n\n\n\u274c Cannot be cached or prefetched\n\n\n\u274c Not idempotent\n\n\n\n\nWhile regular insertion uses JSON to encode the value, bulk insertion\nuses CSV. Simply post to a table route with \nContent-Type: text/csv\n\nand include the names of the columns as the first row. For instance\n\n\nPOST /people\nname,age,height\nJ Doe,62,70\nJonas,10,55\n\n\n\n\nAn empty field (\n,,\n) is coerced to an empty string and the reserved\nword \nNULL\n is mapped to the SQL null value. Note that there should\nbe no spaces between the column names and commas.\n\n\nThe server sends a multipart response for bulk insertions. Each part\ncontains a Location header with URL of each created resource.\n\n\nContent-Type: application/json\nLocation: /festival?name=eq.Venice%20Film%20Festival\n\n\n--postgrest_boundary\nContent-Type: application/json\nLocation: /festival?name=eq.Cannes%20Film%20Festival\n\n\n\n\nUpsertion\n\n\n\n\n\u274c Cannot be cached or prefetched\n\n\n\u2705 Idempotent\n\n\n\n\nTo insert or update a single row use the \nPUT\n verb on a properly\nfiltered table url:\n\n\nPUT /table_name?primary_key=eq.foo\n{ \ncol1\n: \nvalue1\n, \ncol2\n: \nvalue2\n }\n\n\n\n\nThe request must satisfy two things. First all columns must be\nspecified (because a default value might be a changing value which\nwould violate idempotence). Second the URL must match the URL you\nwould use to get the value of the resource. This means that all\nprimary key columns must be included in the filter (there are more\nthan one when the primary key is compound).\n\n\nIf you would like to get the full object back in the response to\nyour request, include the header \nPrefer: return=representation\n.\nIt will of match exactly the object you sent though.\n\n\nBulk Updates\n\n\n\n\n\u274c Cannot be cached or prefetched\n\n\n\u274c Not idempotent\n\n\n\n\nTo change parts of a resource or resources use the \nPATCH\n verb.\nFor instance, here is how to mark all young people as children.\n\n\nPATCH /people?age=lt.13\n{\n  \nperson_type\n: \nchild\n\n}\n\n\n\n\nThis affects any rows matched by the url param filters, overwrites\nany fields specified in in the payload JSON and leaves the other\nfields unaffected. Note that although the payload is not in the\nJSON patch format specified by\n\nRFC6902\n, HTTP does not specify\nwhich patch format to use. Our format is more pleasant, meant for\nbasic field replacements, and not at all \"incorrect.\"\n\n\nDeletion\n\n\n\n\n\u274c Cannot be cached or prefetched\n\n\n\u2705 Idempotent\n\n\n\n\nSimply use the \nDELETE\n verb. All recors that match your filter\nwill be removed. For instance deleting inactive users:\n\n\nDELETE /user?active=eq.false\n\n\n\n\nProtecting Dangerous Actions\n\n\nNotice that it is very easy to delete or update many records at\nonce. In fact forgetting a filter will affect an entire table!\n\n\n\n    \nInvitation to Contribute\n\n\n    \nWe would like to investigate nginx rules to guard dangerous\n    actions, perhaps requiring a confirmation header or query param\n    to perform the action.\n\n\n    \nYou're invited to research this option and contribute to\n    this documentation.", 
            "title": "Writing"
        }, 
        {
            "location": "/api/writing/#updating-data", 
            "text": "Record Creation   \u274c Cannot be cached or prefetched  \u274c Not idempotent   To create a row in a database table post a JSON object whose keys\nare the names of the columns you would like to create. Missing keys\nwill be set to default values when applicable.  POST /table_name\n{  col1 :  value1 ,  col2 :  value2  }  The response will include a  Location  header describing where to\nfind the new object. If you would like to get the full object back\nin the response to your request, include the header  Prefer:\nreturn=representation . That way you won't have to make another\nHTTP call to discover properties that may have been filled in on\nthe server side.  Bulk Insertion   \u274c Cannot be cached or prefetched  \u274c Not idempotent   While regular insertion uses JSON to encode the value, bulk insertion\nuses CSV. Simply post to a table route with  Content-Type: text/csv \nand include the names of the columns as the first row. For instance  POST /people\nname,age,height\nJ Doe,62,70\nJonas,10,55  An empty field ( ,, ) is coerced to an empty string and the reserved\nword  NULL  is mapped to the SQL null value. Note that there should\nbe no spaces between the column names and commas.  The server sends a multipart response for bulk insertions. Each part\ncontains a Location header with URL of each created resource.  Content-Type: application/json\nLocation: /festival?name=eq.Venice%20Film%20Festival\n\n\n--postgrest_boundary\nContent-Type: application/json\nLocation: /festival?name=eq.Cannes%20Film%20Festival  Upsertion   \u274c Cannot be cached or prefetched  \u2705 Idempotent   To insert or update a single row use the  PUT  verb on a properly\nfiltered table url:  PUT /table_name?primary_key=eq.foo\n{  col1 :  value1 ,  col2 :  value2  }  The request must satisfy two things. First all columns must be\nspecified (because a default value might be a changing value which\nwould violate idempotence). Second the URL must match the URL you\nwould use to get the value of the resource. This means that all\nprimary key columns must be included in the filter (there are more\nthan one when the primary key is compound).  If you would like to get the full object back in the response to\nyour request, include the header  Prefer: return=representation .\nIt will of match exactly the object you sent though.  Bulk Updates   \u274c Cannot be cached or prefetched  \u274c Not idempotent   To change parts of a resource or resources use the  PATCH  verb.\nFor instance, here is how to mark all young people as children.  PATCH /people?age=lt.13\n{\n   person_type :  child \n}  This affects any rows matched by the url param filters, overwrites\nany fields specified in in the payload JSON and leaves the other\nfields unaffected. Note that although the payload is not in the\nJSON patch format specified by RFC6902 , HTTP does not specify\nwhich patch format to use. Our format is more pleasant, meant for\nbasic field replacements, and not at all \"incorrect.\"  Deletion   \u274c Cannot be cached or prefetched  \u2705 Idempotent   Simply use the  DELETE  verb. All recors that match your filter\nwill be removed. For instance deleting inactive users:  DELETE /user?active=eq.false  Protecting Dangerous Actions  Notice that it is very easy to delete or update many records at\nonce. In fact forgetting a filter will affect an entire table!  \n     Invitation to Contribute \n\n     We would like to investigate nginx rules to guard dangerous\n    actions, perhaps requiring a confirmation header or query param\n    to perform the action. \n\n     You're invited to research this option and contribute to\n    this documentation.", 
            "title": "Updating Data"
        }, 
        {
            "location": "/admin/security/", 
            "text": "Security\n\n\nSSL\n\n\nDatabase Roles\n\n\nJSON Web Tokens\n\n\nIssuing via sql procedures\n\n\nRow-Level Security\n\n\nSimulated - PostgreSQL \n9.5\n\n\nReal - PostgreSQL \n=9.5\n\n\nBuilding Auth on top of JWT\n\n\nBasic Auth\n\n\nGithub Sign-in", 
            "title": "Security"
        }, 
        {
            "location": "/admin/security/#security", 
            "text": "SSL  Database Roles  JSON Web Tokens  Issuing via sql procedures  Row-Level Security  Simulated - PostgreSQL  9.5  Real - PostgreSQL  =9.5  Building Auth on top of JWT  Basic Auth  Github Sign-in", 
            "title": "Security"
        }, 
        {
            "location": "/admin/versioning/", 
            "text": "API Versioning\n\n\nSchema Search Path\n\n\nChanging a Resource\n\n\nRemoving a Resource\n\n\nAvoiding DB and Client Coupling", 
            "title": "Versioning"
        }, 
        {
            "location": "/admin/versioning/#api-versioning", 
            "text": "Schema Search Path  Changing a Resource  Removing a Resource  Avoiding DB and Client Coupling", 
            "title": "API Versioning"
        }, 
        {
            "location": "/admin/migration/", 
            "text": "Data Migration\n\n\nSqitch\n\n\nTest-Driven Migrations\n\n\nStructural Tests\n\n\nValue Tests with pgTAP", 
            "title": "Migration"
        }, 
        {
            "location": "/admin/migration/#data-migration", 
            "text": "Sqitch  Test-Driven Migrations  Structural Tests  Value Tests with pgTAP", 
            "title": "Data Migration"
        }, 
        {
            "location": "/admin/deployment/", 
            "text": "Deployment\n\n\nHeroku\n\n\nGetting Started\n\n\nUsing Amazon RDS\n\n\nDebian", 
            "title": "Deployment"
        }, 
        {
            "location": "/admin/deployment/#deployment", 
            "text": "Heroku  Getting Started  Using Amazon RDS  Debian", 
            "title": "Deployment"
        }, 
        {
            "location": "/admin/performance/", 
            "text": "Performance\n\n\nBenchmarks\n\n\nCaching\n\n\nQuality of Service\n\n\nTips", 
            "title": "Performance"
        }, 
        {
            "location": "/admin/performance/#performance", 
            "text": "Benchmarks  Caching  Quality of Service  Tips", 
            "title": "Performance"
        }, 
        {
            "location": "/examples/start/", 
            "text": "Getting Started\n\n\nYour First (simple) API\n\n\nLet's start with the simplest thing possible. We will expose some tables directly for reading and writing by anyone.\n\n\nStart by making a database\n\n\ncreatedb demo1\n\n\n\n\nWe'll set it up with a film example (courtesy of \nJonathan Harrington\n). Copy the following into your clipboard:\n\n\nBEGIN;\n\nCREATE TABLE director\n(\n  name text NOT NULL PRIMARY KEY\n);\n\nCREATE TABLE film\n(\n  id serial PRIMARY KEY,\n  title text NOT NULL,\n  year date NOT NULL,\n  director text,\n  rating real NOT NULL DEFAULT 0,\n  language text NOT NULL,\n  CONSTRAINT film_director_fkey FOREIGN KEY (director)\n      REFERENCES director (name) MATCH SIMPLE\n      ON UPDATE CASCADE ON DELETE CASCADE\n);\n\nCREATE TABLE festival\n(\n  name text NOT NULL PRIMARY KEY\n);\n\nCREATE TABLE competition\n(\n  id serial PRIMARY KEY,\n  name text NOT NULL,\n  festival text NOT NULL,\n  year date NOT NULL,\n\n  CONSTRAINT comp_festival_fkey FOREIGN KEY (festival)\n      REFERENCES festival (name) MATCH SIMPLE\n      ON UPDATE CASCADE ON DELETE CASCADE\n);\n\nCREATE TABLE film_nomination\n(\n  id serial PRIMARY KEY,\n  competition integer NOT NULL,\n  film integer NOT NULL,\n  won boolean NOT NULL DEFAULT true,\n\n  CONSTRAINT nomination_competition_fkey FOREIGN KEY (competition)\n     REFERENCES competition (id) MATCH SIMPLE\n     ON UPDATE NO ACTION ON DELETE NO ACTION,\n  CONSTRAINT nomination_film_fkey FOREIGN KEY (film)\n     REFERENCES film (id) MATCH SIMPLE\n     ON UPDATE CASCADE ON DELETE CASCADE\n);\n\nCOMMIT;\n\n\n\n\nApply it to your new database by running\n\n\n# On OS X\npbpaste | psql demo1\n\n# Or Linux\n# xclip -selection clipboard -o | psql demo1\n\n\n\n\nStart the PostgREST server and point it at the new database.\n\n\npostgrest -d demo1 -U postgres -a postgres --v1schema public\n\n\n\n\n\n    \nNote about database users\n\n\n    \nIf you installed PostgreSQL with Homebrew on Mac then the\n    database username may be your own login rather than\n    \npostgres\n.\n\n\n\n\n\nLet's use PostgREST to populate the database. Install a REST client such as \nPostman\n. Now let's insert some data as a bulk post in CSV format:\n\n\nPOST http://localhost:3000/festival\nContent-Type: text/csv\n\nname\nVenice Film Festival\nCannes Film Festival\n\n\n\n\nIn Postman it will look like this\n\n\n\n\nNotice that the post type is \nraw\n and that \nContent-Type: text/csv\n set in the Headers tab. \n\n\nNote that the server returns a multipart response with URL of each created resource.\n\n\nContent-Type: application/json\nLocation: /festival?name=eq.Venice%20Film%20Festival\n\n\n--postgrest_boundary\nContent-Type: application/json\nLocation: /festival?name=eq.Cannes%20Film%20Festival\n\n\n\n\nIf you send a GET request to \n/festival\n it should return\n\n\n[\n  {\n    \nname\n: \nVenice Film Festival\n\n  },\n  {\n    \nname\n: \nCannes Film Festival\n\n  }\n]\n\n\n\n\nNow that you've seen how to do a bulk insert, let's do some more and fully populate the database.\n\n\nPost the following to \n/competition\n:\n\n\nname,festival,year\nGolden Lion,Venice Film Festival,2014-01-01\nPalme d'Or,Cannes Film Festival,2014-01-01\n\n\n\n\nNow \n/director\n:\n\n\nname\nBertrand Bonello\nAtom Egoyan\nDavid Gordon Green\nAndrey Konchalovskiy\nMario Martone\nMike Leigh\nRoy Andersson\nSaverio Costanzo\nAlix Delaporte\nJean-Pierre Dardenne\nXiaoshuai Wang\nKaan M\u00fcjdeci\nTommy Lee Jones\nNuri Bilge Ceylan\nMichel Hazanavicius\nXavier Dolan\nRamin Bahrani\nAlice Rohrwacher\nAndrew Niccol\nRakhshan Bani-Etemad\nDavid Oelhoffen\nBennett Miller\nDavid Cronenberg\nShin'ya Tsukamoto\nJoshua Oppenheimer\nOlivier Assayas\nJean-Luc Godard\nAlejandro Gonz\u00e1lez I\u00f1\u00e1rritu\nBeno\u00eet Jacquot\nFatih Akin\nFrancesco Munzi\nKen Loach\nAbel Ferrara\nXavier Beauvois\nNaomi Kawase\n\n\n\n\nAnd \n/film\n:\n\n\ntitle,year,director,rating,language\nChuang ru zhe,2014-01-01,Xiaoshuai Wang,6.19999981,english\nThe Look of Silence,2014-01-01,Joshua Oppenheimer,8.30000019,Indonesian\nFires on the Plain,2014-01-01,Shin'ya Tsukamoto,5.80000019,Japanese\nFar from Men,2014-01-01,David Oelhoffen,7.5,english\nGood Kill,2014-01-01,Andrew Niccol,6.0999999,english\nLeopardi,2014-01-01,Mario Martone,6.9000001,english\nSivas,2014-01-01,Kaan M\u00fcjdeci,7.69999981,english\nBlack Souls,2014-01-01,Francesco Munzi,7.0999999,english\nThree Hearts,2014-01-01,Beno\u00eet Jacquot,5.80000019,French\nPasolini,2014-01-01,Abel Ferrara,5.80000019,english\nLe dernier coup de marteau,2014-01-01,Alix Delaporte,6.5,english\nManglehorn,2014-01-01,David Gordon Green,7.0999999,english\nHungry Hearts,2014-01-01,Saverio Costanzo,6.4000001,English\nBelye nochi pochtalona Alekseya Tryapitsyna,2014-01-01,Andrey Konchalovskiy,6.9000001,Russian\n99 Homes,2014-01-01,Ramin Bahrani,7.30000019,english\nThe Cut,2014-01-01,Fatih Akin,6,Armenian\nBirdman: Or (The Unexpected Virtue of Ignorance),2014-01-01,Alejandro Gonz\u00e1lez I\u00f1\u00e1rritu,8,English\nLa ran\u00e7on de la gloire,2014-01-01,Xavier Beauvois,5.69999981,French\nA Pigeon Sat on a Branch Reflecting on Existence,2014-01-01,Roy Andersson,7.19999981,english\nTales,2014-01-01,Rakhshan Bani-Etemad,6.80000019,english\nThe Wonders,2014-01-01,Alice Rohrwacher,6.80000019,Italian\nFoxcatcher,2014-01-01,Bennett Miller,7.19999981,English\nMr. Turner,2014-01-01,Mike Leigh,7,English\nJimmy's Hall,2014-01-01,Ken Loach,6.69999981,English\nThe Homesman,2014-01-01,Tommy Lee Jones,6.5999999,English\nThe Captive,2014-01-01,Atom Egoyan,5.9000001,english\nGoodbye to Language,2014-01-01,Jean-Luc Godard,6.19999981,French\nThe Search,2014-01-01,Michel Hazanavicius,6.9000001,French\nStill the Water,2014-01-01,Naomi Kawase,6.9000001,Japanese\nMommy,2014-01-01,Xavier Dolan,8.30000019,French\n\nTwo Days, One Night\n,2014-01-01,Jean-Pierre Dardenne,7.4000001,French\nMaps to the Stars,2014-01-01,David Cronenberg,6.4000001,English\nSaint Laurent,2014-01-01,Bertrand Bonello,6.5,French\nClouds of Sils Maria,2014-01-01,Olivier Assayas,6.9000001,english\nWinter Sleep,2014-01-01,Nuri Bilge Ceylan,8.5,Turkish\n\n\n\n\nFinally \n/film_nomination\n:\n\n\ncompetition,film,won\n1,1,f\n1,2,f\n1,3,f\n1,4,f\n1,5,f\n1,6,f\n1,7,f\n1,8,f\n1,9,f\n1,10,f\n1,11,f\n1,12,f\n1,13,f\n1,14,f\n1,15,f\n1,16,f\n1,17,f\n1,18,f\n1,19,f\n1,20,f\n2,21,f\n2,22,f\n2,23,f\n2,24,f\n2,25,f\n2,26,f\n2,27,f\n2,28,f\n2,29,f\n2,30,f\n2,31,f\n2,32,f\n2,33,f\n2,34,f\n2,35,f\n\n\n\n\nAt this point nominations are fully specified but it's not a convenient interface for a rest client. Let's make a view they can use. Paste this into \npsql demo1\n.\n\n\ncreate or replace view nomination as\nselect comp.festival,  \n       comp.name as competition,\n       comp.year,\n       film.title,\n       film.director,\n       film.rating\n from film_nomination as nom\n left join film on nom.film = film.id\n left join competition as comp on nom.competition = comp.id\n order by comp.year desc, comp.festival, competition;\n\n\n\n\nTime to try it out. Let's get the contents of the new view, ordered by film rating\n\n\nGET http://localhost:3000/nomination?order=rating.desc\n\n\n\n\nIf you find it more human readable, add an \nAccept: text/csv\n header.\n\n\nReleasing a New Version\n\n\nSuppose we want this endpoint to cater to those moviegoers with attention deficit disorder. In today's busy world we don't have time to read an extra couple words or compare nuanced reviews. In API version two we will truncate the names and round the ratings!\n\n\nEach version lives in a numbered schema, so let's make a schema for version two.\n\n\nCREATE SCHEMA \n2\n;\nGRANT USAGE ON SCHEMA \n2\n TO PUBLIC;\nALTER DATABASE demo1 SET search_path = \n2\n, \npublic\n;\n\n\n\n\nTo override the \nfilms\n endpoint create a view in the \"2\" schema with that name:\n\n\ncreate or replace view \n2\n.film as\nselect id, substring(f.title from 1 for 10) as title,\n       year, director, round(f.rating) as rating, language\nfrom \npublic\n.film as f;\n\n\n\n\nWe select the desired version as part of content negotiation. Try this get request:\n\n\nGET http://localhost:3000/film\nAccept: text/csv; version=2\n\n\n\n\nThen try toggling the version string in the Accept header and watch the results change. Pretty good, now how about writing values? PostgreSQL's nice feature called auto-updatable views allows writes to pass through views. Sadly this view is not eligible because truncation and rounding cannot be uniquely reversed. If we attempt to post a new result it complains:\n\n\n{\n  \nhint\n: null,\n  \ndetails\n: \nView columns that are not columns of their base relation are not updatable.\n,\n  \ncode\n: \n0A000\n,\n  \nmessage\n: \ncannot insert into column \\\ntitle\\\n of view \\\nfilm\\\n\n}\n\n\n\n\nThis is a case where we need explicit triggers\n\n\n-- TODO - FIX THIS\n\n-- CREATE OR REPLACE RULE insert_v2_films AS\n--   ON INSERT TO \n2\n.film\n--   DO INSTEAD\n--      INSERT INTO public.film (id, title, year, director, rating, language)\n--      VALUES (NEW.id,     NEW.title,\n--              NEW.year,   NEW.director,\n--              NEW.rating, NEW.language)\n--      RETURNING public.film.*;", 
            "title": "Getting Started"
        }, 
        {
            "location": "/examples/start/#getting-started", 
            "text": "Your First (simple) API  Let's start with the simplest thing possible. We will expose some tables directly for reading and writing by anyone.  Start by making a database  createdb demo1  We'll set it up with a film example (courtesy of  Jonathan Harrington ). Copy the following into your clipboard:  BEGIN;\n\nCREATE TABLE director\n(\n  name text NOT NULL PRIMARY KEY\n);\n\nCREATE TABLE film\n(\n  id serial PRIMARY KEY,\n  title text NOT NULL,\n  year date NOT NULL,\n  director text,\n  rating real NOT NULL DEFAULT 0,\n  language text NOT NULL,\n  CONSTRAINT film_director_fkey FOREIGN KEY (director)\n      REFERENCES director (name) MATCH SIMPLE\n      ON UPDATE CASCADE ON DELETE CASCADE\n);\n\nCREATE TABLE festival\n(\n  name text NOT NULL PRIMARY KEY\n);\n\nCREATE TABLE competition\n(\n  id serial PRIMARY KEY,\n  name text NOT NULL,\n  festival text NOT NULL,\n  year date NOT NULL,\n\n  CONSTRAINT comp_festival_fkey FOREIGN KEY (festival)\n      REFERENCES festival (name) MATCH SIMPLE\n      ON UPDATE CASCADE ON DELETE CASCADE\n);\n\nCREATE TABLE film_nomination\n(\n  id serial PRIMARY KEY,\n  competition integer NOT NULL,\n  film integer NOT NULL,\n  won boolean NOT NULL DEFAULT true,\n\n  CONSTRAINT nomination_competition_fkey FOREIGN KEY (competition)\n     REFERENCES competition (id) MATCH SIMPLE\n     ON UPDATE NO ACTION ON DELETE NO ACTION,\n  CONSTRAINT nomination_film_fkey FOREIGN KEY (film)\n     REFERENCES film (id) MATCH SIMPLE\n     ON UPDATE CASCADE ON DELETE CASCADE\n);\n\nCOMMIT;  Apply it to your new database by running  # On OS X\npbpaste | psql demo1\n\n# Or Linux\n# xclip -selection clipboard -o | psql demo1  Start the PostgREST server and point it at the new database.  postgrest -d demo1 -U postgres -a postgres --v1schema public  \n     Note about database users \n\n     If you installed PostgreSQL with Homebrew on Mac then the\n    database username may be your own login rather than\n     postgres .   Let's use PostgREST to populate the database. Install a REST client such as  Postman . Now let's insert some data as a bulk post in CSV format:  POST http://localhost:3000/festival\nContent-Type: text/csv\n\nname\nVenice Film Festival\nCannes Film Festival  In Postman it will look like this   Notice that the post type is  raw  and that  Content-Type: text/csv  set in the Headers tab.   Note that the server returns a multipart response with URL of each created resource.  Content-Type: application/json\nLocation: /festival?name=eq.Venice%20Film%20Festival\n\n\n--postgrest_boundary\nContent-Type: application/json\nLocation: /festival?name=eq.Cannes%20Film%20Festival  If you send a GET request to  /festival  it should return  [\n  {\n     name :  Venice Film Festival \n  },\n  {\n     name :  Cannes Film Festival \n  }\n]  Now that you've seen how to do a bulk insert, let's do some more and fully populate the database.  Post the following to  /competition :  name,festival,year\nGolden Lion,Venice Film Festival,2014-01-01\nPalme d'Or,Cannes Film Festival,2014-01-01  Now  /director :  name\nBertrand Bonello\nAtom Egoyan\nDavid Gordon Green\nAndrey Konchalovskiy\nMario Martone\nMike Leigh\nRoy Andersson\nSaverio Costanzo\nAlix Delaporte\nJean-Pierre Dardenne\nXiaoshuai Wang\nKaan M\u00fcjdeci\nTommy Lee Jones\nNuri Bilge Ceylan\nMichel Hazanavicius\nXavier Dolan\nRamin Bahrani\nAlice Rohrwacher\nAndrew Niccol\nRakhshan Bani-Etemad\nDavid Oelhoffen\nBennett Miller\nDavid Cronenberg\nShin'ya Tsukamoto\nJoshua Oppenheimer\nOlivier Assayas\nJean-Luc Godard\nAlejandro Gonz\u00e1lez I\u00f1\u00e1rritu\nBeno\u00eet Jacquot\nFatih Akin\nFrancesco Munzi\nKen Loach\nAbel Ferrara\nXavier Beauvois\nNaomi Kawase  And  /film :  title,year,director,rating,language\nChuang ru zhe,2014-01-01,Xiaoshuai Wang,6.19999981,english\nThe Look of Silence,2014-01-01,Joshua Oppenheimer,8.30000019,Indonesian\nFires on the Plain,2014-01-01,Shin'ya Tsukamoto,5.80000019,Japanese\nFar from Men,2014-01-01,David Oelhoffen,7.5,english\nGood Kill,2014-01-01,Andrew Niccol,6.0999999,english\nLeopardi,2014-01-01,Mario Martone,6.9000001,english\nSivas,2014-01-01,Kaan M\u00fcjdeci,7.69999981,english\nBlack Souls,2014-01-01,Francesco Munzi,7.0999999,english\nThree Hearts,2014-01-01,Beno\u00eet Jacquot,5.80000019,French\nPasolini,2014-01-01,Abel Ferrara,5.80000019,english\nLe dernier coup de marteau,2014-01-01,Alix Delaporte,6.5,english\nManglehorn,2014-01-01,David Gordon Green,7.0999999,english\nHungry Hearts,2014-01-01,Saverio Costanzo,6.4000001,English\nBelye nochi pochtalona Alekseya Tryapitsyna,2014-01-01,Andrey Konchalovskiy,6.9000001,Russian\n99 Homes,2014-01-01,Ramin Bahrani,7.30000019,english\nThe Cut,2014-01-01,Fatih Akin,6,Armenian\nBirdman: Or (The Unexpected Virtue of Ignorance),2014-01-01,Alejandro Gonz\u00e1lez I\u00f1\u00e1rritu,8,English\nLa ran\u00e7on de la gloire,2014-01-01,Xavier Beauvois,5.69999981,French\nA Pigeon Sat on a Branch Reflecting on Existence,2014-01-01,Roy Andersson,7.19999981,english\nTales,2014-01-01,Rakhshan Bani-Etemad,6.80000019,english\nThe Wonders,2014-01-01,Alice Rohrwacher,6.80000019,Italian\nFoxcatcher,2014-01-01,Bennett Miller,7.19999981,English\nMr. Turner,2014-01-01,Mike Leigh,7,English\nJimmy's Hall,2014-01-01,Ken Loach,6.69999981,English\nThe Homesman,2014-01-01,Tommy Lee Jones,6.5999999,English\nThe Captive,2014-01-01,Atom Egoyan,5.9000001,english\nGoodbye to Language,2014-01-01,Jean-Luc Godard,6.19999981,French\nThe Search,2014-01-01,Michel Hazanavicius,6.9000001,French\nStill the Water,2014-01-01,Naomi Kawase,6.9000001,Japanese\nMommy,2014-01-01,Xavier Dolan,8.30000019,French Two Days, One Night ,2014-01-01,Jean-Pierre Dardenne,7.4000001,French\nMaps to the Stars,2014-01-01,David Cronenberg,6.4000001,English\nSaint Laurent,2014-01-01,Bertrand Bonello,6.5,French\nClouds of Sils Maria,2014-01-01,Olivier Assayas,6.9000001,english\nWinter Sleep,2014-01-01,Nuri Bilge Ceylan,8.5,Turkish  Finally  /film_nomination :  competition,film,won\n1,1,f\n1,2,f\n1,3,f\n1,4,f\n1,5,f\n1,6,f\n1,7,f\n1,8,f\n1,9,f\n1,10,f\n1,11,f\n1,12,f\n1,13,f\n1,14,f\n1,15,f\n1,16,f\n1,17,f\n1,18,f\n1,19,f\n1,20,f\n2,21,f\n2,22,f\n2,23,f\n2,24,f\n2,25,f\n2,26,f\n2,27,f\n2,28,f\n2,29,f\n2,30,f\n2,31,f\n2,32,f\n2,33,f\n2,34,f\n2,35,f  At this point nominations are fully specified but it's not a convenient interface for a rest client. Let's make a view they can use. Paste this into  psql demo1 .  create or replace view nomination as\nselect comp.festival,  \n       comp.name as competition,\n       comp.year,\n       film.title,\n       film.director,\n       film.rating\n from film_nomination as nom\n left join film on nom.film = film.id\n left join competition as comp on nom.competition = comp.id\n order by comp.year desc, comp.festival, competition;  Time to try it out. Let's get the contents of the new view, ordered by film rating  GET http://localhost:3000/nomination?order=rating.desc  If you find it more human readable, add an  Accept: text/csv  header.  Releasing a New Version  Suppose we want this endpoint to cater to those moviegoers with attention deficit disorder. In today's busy world we don't have time to read an extra couple words or compare nuanced reviews. In API version two we will truncate the names and round the ratings!  Each version lives in a numbered schema, so let's make a schema for version two.  CREATE SCHEMA  2 ;\nGRANT USAGE ON SCHEMA  2  TO PUBLIC;\nALTER DATABASE demo1 SET search_path =  2 ,  public ;  To override the  films  endpoint create a view in the \"2\" schema with that name:  create or replace view  2 .film as\nselect id, substring(f.title from 1 for 10) as title,\n       year, director, round(f.rating) as rating, language\nfrom  public .film as f;  We select the desired version as part of content negotiation. Try this get request:  GET http://localhost:3000/film\nAccept: text/csv; version=2  Then try toggling the version string in the Accept header and watch the results change. Pretty good, now how about writing values? PostgreSQL's nice feature called auto-updatable views allows writes to pass through views. Sadly this view is not eligible because truncation and rounding cannot be uniquely reversed. If we attempt to post a new result it complains:  {\n   hint : null,\n   details :  View columns that are not columns of their base relation are not updatable. ,\n   code :  0A000 ,\n   message :  cannot insert into column \\ title\\  of view \\ film\\ \n}  This is a case where we need explicit triggers  -- TODO - FIX THIS\n\n-- CREATE OR REPLACE RULE insert_v2_films AS\n--   ON INSERT TO  2 .film\n--   DO INSTEAD\n--      INSERT INTO public.film (id, title, year, director, rating, language)\n--      VALUES (NEW.id,     NEW.title,\n--              NEW.year,   NEW.director,\n--              NEW.rating, NEW.language)\n--      RETURNING public.film.*;", 
            "title": "Getting Started"
        }
    ]
}